# -*- coding: utf-8 -*-
"""Frist Project NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uy6gqmHkP9aKuOpwto50VEZQM7LqRz8N
"""

#memasukan library
import os,zipfile
import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/LanguageIdentificationdataset.csv')

df.head()

#cek value setiap language
df['language'].value_counts()

# Mengambil 4 language saja
df = df[~df['language'].isin(['Arabic', 'Thai', 'Turkish', 'Urdu', 'Chinese', 'Dutch',	'Estonian', 'French', 'Hindi', 'Japanese', 'Korean', 'Persian', 'Portugese', 'Pushto', 'Romanian', 'Russian', 'Swedish', 'Tamil'])]
df['language'].value_counts()

category = pd.get_dummies(df.language)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='language')
df_baru

teks = df_baru['Text'].values
label = df_baru[['Latin', 'Indonesian', 'Spanish', 'English']].values

from sklearn.model_selection import train_test_split
teks_latih, teks_test, label_latih, label_test = train_test_split(teks, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x', filters='!"#$%&()*+,-./:;<=>@[\]^_`{|}~ ')
tokenizer.fit_on_texts(teks_latih) 
tokenizer.fit_on_texts(teks_test)
 
sekuens_latih = tokenizer.texts_to_sequences(teks_latih)
sekuens_test = tokenizer.texts_to_sequences(teks_test)
 
padded_latih = pad_sequences(sekuens_latih,
                             padding='post',
                             maxlen=100,
                             truncating='post')
padded_test = pad_sequences(sekuens_test,
                            padding='post',
                            maxlen=100,
                            truncating='post')

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(4, activation='softmax')
])

Adam(learning_rate=0.00146, name='Adam')
model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy'])
model.summary()

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy') > 0.9):
      print("\nTraining dihentikan karena accuracy telah mencapai 90%")
      self.model.stop_training = True

callbacks = myCallback()

history = model.fit(
    padded_latih,
    label_latih,
    epochs=30, 
    validation_data=(padded_test, label_test),
    #validation_steps=30,
    verbose=2,
    batch_size=27,
    callbacks=[callbacks]
)

from matplotlib import pyplot as plt
#loss train & validation
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Plot')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="upper right")
plt.show()

#accuracy train & validation
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Plot')
plt.ylabel('Value')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.show()

"""#Nama : Abdul Mukhit Murtadho
#Email : muchitabdul11@gmail.com
#No. Registrasi : 1494037162101-2090
"""